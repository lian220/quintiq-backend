# 스케줄러 운영 가이드

**목적**: QuantIQ 스케줄러 관리 및 운영 실무 가이드
**대상**: 시스템 관리자, DevOps 엔지니어
**작성일**: 2026-01-31
**최종 업데이트**: 2026-02-01 (v2.0 - Vertex AI 통합 및 스케줄 최적화)

---

## 📋 목차

1. [스케줄 구성](#스케줄-구성)
2. [스케줄러 시작/중지](#스케줄러-시작중지)
3. [스케줄 관리](#스케줄-관리)
4. [모니터링](#모니터링)
5. [로그 확인](#로그-확인)
6. [데이터베이스 직접 관리](#데이터베이스-직접-관리)
7. [트러블슈팅](#트러블슈팅)
8. [성능 튜닝](#성능-튜닝)

---

## 스케줄 구성

### 전체 스케줄 타임라인

```
일일 스케줄 (KST 기준):

22:00 → 경제 데이터 수집 + Vertex AI 예측 (EconomicDataUpdate2JobAdapter)
        📊 미국 경제 지표 발표 타이밍 최적화
        - CPI/NFP 발표 (21:30) 직후
        - ISM PMI 발표 (23:00) 직전

        [1단계] 경제 데이터 수집
        - FRED 경제 지표 (CPI, NFP, ISM PMI 등)
        - Yahoo Finance 시장 데이터
        - MongoDB daily_stock_data 업데이트

        [2단계] Vertex AI 예측 실행
        - Python 스크립트 (run_predict_vertex_ai.py)
        - Google Vertex AI CustomJob 생성
        - GPU Fine-tuning (T4 기본, L4 DWS)
        - 3-5분 소요 (기존 25-30분 대비 83% 단축)
        - GCS 모델 저장 (gs://quantiq-ml-models/)
        - 예측 결과 MongoDB 저장

23:05 → 예측 검증 (ParallelAnalysisJob)
        🔍 Vertex AI 예측 결과 검증
        - ISM PMI (23:00) 발표 직후
        - 기술적 지표 분석으로 예측 검증
        - 감정 분석 (TODO)
        - 매수 신호 신뢰도 필터링

00:30 → 자동 매수 (AutoBuyJobAdapter)
        💰 미국 장 개장 1시간 후 (변동성 안정화)
        - 미국 정규장 개장: 23:30 (09:30 ET)
        - 초기 변동성 회피 (첫 30분 일일 최고가의 24%)
        - 1시간 후 트렌드 확정 구간 진입
        - Vertex AI 예측 결과 조회
        - 매수 신호 필터링 (신뢰도 임계값)
        - KIS API 매수 주문 실행

01:30 → 매수 후 검증 (CombinedAnalysisJobAdapter)
        ✅ 매수 결정 재평가
        - 매수 1시간 후 기술적 분석
        - 기술적 분석 70% + 감정 분석 30%
        - 매수 유지/취소 판단

02:30 → 감정 분석 재검증 (SentimentAnalysisJob)
        📰 뉴스 감정 분석
        - 매수 2시간 후 최종 검증
        - 뉴스 감정 분석 (TODO)
        - 매수 결정 최종 재평가

06:30 → 미체결 주문 정리 (CleanupOrdersJobAdapter)
        🧹 장 마감 후 정리
        - 미체결 주문 취소
        - 실패 주문 정리

07:00 → 포트폴리오 수익률 보고 (PortfolioProfitReportJobAdapter)
        📊 일일 실적 리포트
        - 일일 수익률 계산
        - Slack 알림 발송

매 1분 → 자동 매도 체크 (AutoSellJobAdapter)
        🔄 실시간 매도 모니터링
        - 손절/익절 조건 확인
        - 매도 주문 실행 (미국 시장 시간만)
        - 평일 09:30-16:00 ET (23:30-06:00 KST)
```

### 스케줄 최적화 근거

#### 22:00 - 경제 데이터 수집 + Vertex AI 예측

**미국 경제 지표 발표 타이밍:**
- **CPI (소비자물가지수)**: 매월 중순, 21:30 KST (08:30 ET)
- **NFP (비농업 고용)**: 매월 첫 금요일, 21:30 KST (08:30 ET)
- **ISM PMI (제조업 지수)**: 매월 초, 23:00 KST (10:00 ET)

**22:00 실행 이유:**
- CPI/NFP 발표(21:30) 직후, ISM PMI(23:00) 직전
- 주요 경제 지표 발표 사이 실행으로 최신 데이터 확보
- Vertex AI Fine-tuning 3-5분 소요로 23:00 전 완료

**Vertex AI 통합 상세:**
- **플랫폼**: Google Cloud Vertex AI Custom Training Jobs
- **모델**: Transformer (2-layer, Multi-head Attention)
- **GPU**: NVIDIA Tesla T4 (기본), L4 (DWS 지원)
- **저장소**: GCS (gs://quantiq-ml-models/models/transformer_stock_model.h5)
- **Fine-tuning 모드**: 기존 모델 로드 → 5 epochs 학습 (vs 전체 학습 50 epochs)
- **데이터**: 최근 24개월 데이터만 로드 (메모리 최적화)
- **예상 비용**: ~$0.03/day (~$1/month)
- **성능 개선**: 25-30분 → 3-5분 (83% 단축)

#### 00:30 - 자동 매수

**미국 시장 변동성 패턴:**
- **첫 30분 (23:30-00:00)**: 일일 최고가의 24% 발생 (가장 높은 변동성)
- **30분~1시간 (00:00-00:30)**: 변동성 감소, 트렌드 확정 시작
- **1시간 이후 (00:30~)**: 안정적인 트렌드 진입 구간

**00:30 실행 이유:**
- 초기 변동성 회피 → 안전한 진입 가격 확보
- 트렌드 확정 후 매수 → 잘못된 신호 감소
- Vertex AI 예측 + 기술적 검증 완료 상태

### Job 목록

| # | Job 이름 | 실행 시간 | Cron 표현식 | 역할 | 상태 |
|---|----------|----------|-------------|------|------|
| 1 | economicDataUpdate2Job | 22:00 (매일) | `0 0 22 * * ?` | 경제 데이터 수집 + Vertex AI 예측 | ✅ 완료 |
| 2 | parallelAnalysisJob | 23:05 (매일) | `0 5 23 * * ?` | 예측 검증 (기술적 지표 + 감정 분석) | ⚠️ TODO |
| 3 | autoBuyJob | 00:30 (매일) | `0 30 0 * * ?` | 자동 매수 (장 개장 1시간 후) | ✅ 완료 |
| 4 | combinedAnalysisJob | 01:30 (매일) | `0 30 1 * * ?` | 매수 후 검증 (기술 70% + 감정 30%) | ✅ 완료 |
| 5 | sentimentAnalysisJob | 02:30 (매일) | `0 30 2 * * ?` | 뉴스 감정 분석 (매수 재검증) | ⚠️ TODO |
| 6 | cleanupOrdersJob | 06:30 (매일) | `0 30 6 * * ?` | 미체결 주문 정리 | ✅ 완료 |
| 7 | portfolioProfitReportJob | 07:00 (매일) | `0 0 7 * * ?` | 포트폴리오 수익률 보고 | ✅ 완료 |
| 8 | autoSellJob | **매 1분** | SimpleSchedule | 자동 매도 체크 (미국 시장 시간만) | ✅ 완료 |

---

## 스케줄러 시작/중지

### REST API를 통한 제어

#### 스케줄러 시작

```bash
curl -X POST http://localhost:8080/api/scheduler/start

# 응답
{
  "success": true,
  "message": "스케줄러가 시작되었습니다."
}
```

#### 스케줄러 중지

```bash
curl -X POST http://localhost:8080/api/scheduler/stop

# 응답
{
  "success": true,
  "message": "스케줄러가 중지되었습니다."
}
```

#### 스케줄러 상태 조회

```bash
curl -X GET http://localhost:8080/api/scheduler/status

# 응답
{
  "isRunning": true,
  "scheduledJobCount": 2,
  "activeTriggerCount": 2
}
```

### Docker를 통한 제어

#### 스케줄러 재시작

```bash
# quantiq-core 컨테이너 재시작
docker-compose restart quantiq-core

# 로그 확인
docker-compose logs -f quantiq-core | grep -i "scheduler"
```

#### 스케줄러 포함 전체 재시작

```bash
# 전체 시스템 재시작
docker-compose down
docker-compose up -d

# 스케줄러 시작 확인
docker-compose logs quantiq-core | grep "Scheduler started"
```

### 애플리케이션 설정

#### application.yml 설정

```yaml
spring:
  quartz:
    # 스케줄러 자동 시작 여부
    auto-startup: true

    # 시작 지연 시간 (초)
    startup-delay: 10

    # Job 실행 대기 시 오버라이드 여부
    overwrite-existing-jobs: false
```

---

## 스케줄 관리

### 등록된 스케줄 조회

#### 모든 스케줄 조회

```bash
curl -X GET http://localhost:8080/api/scheduler/schedules

# 응답
{
  "economicDataUpdateTrigger": {
    "triggerName": "economicDataUpdateTrigger",
    "jobName": "economicDataUpdateJob",
    "nextFireTime": "2026-01-31T06:05:00.000+00:00",
    "previousFireTime": "2026-01-30T06:05:00.000+00:00",
    "state": "WAITING"
  },
  "parallelAnalysisTrigger": {
    "triggerName": "parallelAnalysisTrigger",
    "jobName": "parallelAnalysisJob",
    "nextFireTime": "2026-01-31T23:05:00.000+00:00",
    "previousFireTime": "2026-01-30T23:05:00.000+00:00",
    "state": "WAITING"
  }
}
```

### 스케줄 일시 중지 (Pause)

#### 특정 스케줄 일시 중지

```bash
curl -X POST http://localhost:8080/api/scheduler/schedules/economicDataUpdateTrigger/pause

# 응답
{
  "success": true,
  "message": "스케줄이 일시 중지되었습니다."
}
```

#### 효과
- 해당 Trigger의 상태가 `WAITING` → `PAUSED`로 변경
- 다음 실행 시간이 되어도 Job이 실행되지 않음
- Resume 전까지 계속 중지 상태 유지

### 스케줄 재개 (Resume)

```bash
curl -X POST http://localhost:8080/api/scheduler/schedules/economicDataUpdateTrigger/resume

# 응답
{
  "success": true,
  "message": "스케줄이 재개되었습니다."
}
```

#### 효과
- Trigger 상태가 `PAUSED` → `WAITING`로 변경
- 다음 실행 시간에 정상적으로 Job 실행

### Trigger 상태 설명

| 상태 | 설명 |
|------|------|
| `WAITING` | 다음 실행을 기다리는 정상 상태 |
| `PAUSED` | 일시 중지된 상태 (실행 안 됨) |
| `ACQUIRED` | 실행을 위해 획득된 상태 |
| `EXECUTING` | 현재 실행 중 |
| `COMPLETE` | 실행 완료 (재실행 없음) |
| `BLOCKED` | 이전 실행이 아직 완료되지 않아 대기 중 |
| `ERROR` | 오류 상태 |

---

## 모니터링

### 스케줄 실행 상태 모니터링

#### 다음 실행 시간 확인

```bash
# PostgreSQL 쿼리
docker-compose exec postgresql psql -U quantiq_user -d quantiq << 'EOF'
SELECT
    trigger_name,
    to_timestamp(next_fire_time / 1000) AT TIME ZONE 'Asia/Seoul' as next_run_kst,
    to_timestamp(prev_fire_time / 1000) AT TIME ZONE 'Asia/Seoul' as prev_run_kst,
    trigger_state
FROM quartz_triggers
ORDER BY next_fire_time;
EOF
```

**출력 예시:**
```
        trigger_name         |     next_run_kst     |     prev_run_kst     | trigger_state
-----------------------------+----------------------+----------------------+--------------
 economicDataUpdateTrigger   | 2026-01-31 06:05:00  | 2026-01-30 06:05:00  | WAITING
 parallelAnalysisTrigger     | 2026-01-31 23:05:00  | 2026-01-30 23:05:00  | WAITING
```

#### 실행 중인 Job 확인

```bash
docker-compose exec postgresql psql -U quantiq_user -d quantiq << 'EOF'
SELECT
    trigger_name,
    job_name,
    to_timestamp(fired_time / 1000) AT TIME ZONE 'Asia/Seoul' as fired_time_kst,
    state,
    instance_name
FROM quartz_fired_triggers
WHERE state = 'EXECUTING';
EOF
```

### 실행 이력 조회

#### Job 실행 통계

```bash
# 최근 실행 이력 (애플리케이션 로그 기반)
docker-compose logs quantiq-core --since 24h | grep -E "(경제 데이터|병렬 분석)" | grep "시작\|완료\|실패"
```

#### 실행 성공률 확인

```bash
# 성공한 실행
docker-compose logs quantiq-core --since 7d | grep "✅.*완료" | wc -l

# 실패한 실행
docker-compose logs quantiq-core --since 7d | grep "❌.*실패" | wc -l
```

### Grafana 대시보드 (권장)

#### 모니터링 지표

- **스케줄러 상태**: `isRunning`, `scheduledJobCount`
- **Job 실행 횟수**: 성공/실패 카운트
- **Job 실행 시간**: 평균/최대 실행 시간
- **에러율**: 실패 Job 비율

#### Prometheus 메트릭 예시 (향후 구현)

```yaml
# 스케줄러 상태
quantiq_scheduler_running{instance="quantiq-core"} 1

# Job 실행 카운터
quantiq_job_executions_total{job="economicDataUpdate", status="success"} 30
quantiq_job_executions_total{job="economicDataUpdate", status="failure"} 2

# Job 실행 시간
quantiq_job_execution_duration_seconds{job="economicDataUpdate"} 45.3
```

---

## 로그 확인

### 스케줄러 시작 로그

```bash
docker-compose logs quantiq-core | grep "Scheduler"

# 예시 출력
[2026-01-31 00:00:15] INFO  o.q.c.QuartzScheduler - Scheduler QuantIQScheduler_$_AUTO started.
[2026-01-31 00:00:15] INFO  o.q.c.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.2) ...
```

### Job 실행 로그

#### 경제 데이터 수집 + Vertex AI 예측 Job

```bash
docker-compose logs -f quantiq-core | grep -E "경제 데이터|Vertex AI"

# 예시 출력
[2026-02-01 22:00:00] INFO  EconomicDataUpdate2JobAdapter - ================================================================================
[2026-02-01 22:00:00] INFO  EconomicDataUpdate2JobAdapter - 경제 데이터 재수집 + Vertex AI 예측 시작 (22:00)
[2026-02-01 22:00:00] INFO  EconomicDataUpdate2JobAdapter - ================================================================================
[2026-02-01 22:00:05] INFO  EconomicDataUpdate2JobAdapter - ✅ 경제 데이터 재수집 완료: success
[2026-02-01 22:00:05] INFO  EconomicDataUpdate2JobAdapter - 🚀 Vertex AI 예측 실행 시작...
[2026-02-01 22:00:05] INFO  EconomicDataUpdate2JobAdapter - Python 스크립트 실행: .../run_predict_vertex_ai.py
[2026-02-01 22:03:45] INFO  EconomicDataUpdate2JobAdapter - ✅ Vertex AI 예측 실행 완료
[2026-02-01 22:03:45] INFO  EconomicDataUpdate2JobAdapter - ================================================================================
```

**Vertex AI Job 상세 로그:**
```bash
# Python 스크립트 실행 로그 확인
docker-compose logs -f quantiq-core | grep "run_predict_vertex_ai"

# 예시 출력
[INFO] .env 파일 로드 완료
[INFO] GCS에서 최신 버전의 패키지를 찾는 중...
[INFO] ✅ 최신 버전 패키지 발견: v3
[INFO] CustomJob 객체 생성 완료
[INFO] CustomJob 실행 시작 (일반 스케줄링)
[INFO] Job 상태: JobState.JOB_STATE_SUCCEEDED
[INFO] ✅ Job 실행이 성공적으로 완료되었습니다!
```

#### 예측 검증 Job

```bash
docker-compose logs -f quantiq-core | grep "병렬 분석"

# 예시 출력
[2026-02-01 23:05:00] INFO  ParallelAnalysisJob - ============================================================
[2026-02-01 23:05:00] INFO  ParallelAnalysisJob - 병렬 분석 시작 (23:05) [예측 검증 모드]
[2026-02-01 23:05:00] INFO  ParallelAnalysisJob - ============================================================
[2026-02-01 23:05:00] INFO  ParallelAnalysisJob - 병렬 분석 완료
[2026-02-01 23:05:00] INFO  ParallelAnalysisJob - ============================================================
```

#### 자동 매수 Job

```bash
docker-compose logs -f quantiq-core | grep "자동 매수"

# 예시 출력
[2026-02-01 00:30:00] INFO  AutoBuyJobAdapter - ================================================================================
[2026-02-01 00:30:00] INFO  AutoBuyJobAdapter - 자동 매수 시작 (00:30) [미국 장 개장 1시간 후]
[2026-02-01 00:30:00] INFO  AutoBuyJobAdapter - ================================================================================
[2026-02-01 00:30:05] INFO  AutoBuyJobAdapter - 📊 Vertex AI 예측 결과 조회 완료
[2026-02-01 00:30:10] INFO  AutoBuyJobAdapter - ✅ 매수 주문 실행 완료: 5건
[2026-02-01 00:30:10] INFO  AutoBuyJobAdapter - ================================================================================
```

### 에러 로그 필터링

```bash
# 스케줄러 관련 에러만 확인
docker-compose logs quantiq-core --since 24h | grep -i "error.*scheduler\|error.*job"

# Job 실행 실패 로그
docker-compose logs quantiq-core --since 24h | grep "❌"
```

### 로그 파일 저장

```bash
# 오늘의 스케줄러 로그 저장
docker-compose logs quantiq-core --since $(date +%Y-%m-%d) > scheduler-$(date +%Y%m%d).log

# 에러 로그만 저장
docker-compose logs quantiq-core --since 7d | grep -i error > scheduler-errors.log
```

---

## 데이터베이스 직접 관리

### PostgreSQL 접속

```bash
docker-compose exec postgresql psql -U quantiq_user -d quantiq
```

### 유용한 쿼리

#### 1. 모든 Job 목록 조회

```sql
SELECT
    job_name,
    job_group,
    job_class_name,
    is_durable,
    is_nonconcurrent
FROM quartz_job_details;
```

#### 2. 스케줄 상세 정보

```sql
SELECT
    t.trigger_name,
    t.job_name,
    t.trigger_state,
    ct.cron_expression,
    ct.time_zone_id,
    to_timestamp(t.next_fire_time / 1000) AT TIME ZONE 'Asia/Seoul' as next_run,
    to_timestamp(t.prev_fire_time / 1000) AT TIME ZONE 'Asia/Seoul' as prev_run
FROM quartz_triggers t
LEFT JOIN quartz_cron_triggers ct
    ON t.trigger_name = ct.trigger_name
ORDER BY t.next_fire_time;
```

#### 3. 실행 중인 Job 확인

```sql
SELECT
    job_name,
    trigger_name,
    instance_name,
    to_timestamp(fired_time / 1000) AT TIME ZONE 'Asia/Seoul' as fired_time,
    state
FROM quartz_fired_triggers
WHERE state = 'EXECUTING';
```

#### 4. 일시 중지된 스케줄 확인

```sql
SELECT
    trigger_name,
    job_name,
    trigger_state
FROM quartz_triggers
WHERE trigger_state = 'PAUSED';
```

#### 5. 스케줄러 클러스터 상태

```sql
SELECT
    instance_name,
    to_timestamp(last_checkin_time / 1000) AT TIME ZONE 'Asia/Seoul' as last_checkin,
    checkin_interval
FROM quartz_scheduler_state;
```

### 수동 스케줄 조작 (주의)

#### Trigger 수동 일시 중지

```sql
-- ⚠️ REST API 사용 권장, 직접 DB 조작은 비상시에만
UPDATE quartz_triggers
SET trigger_state = 'PAUSED'
WHERE trigger_name = 'economicDataUpdateTrigger';
```

#### Trigger 수동 재개

```sql
UPDATE quartz_triggers
SET trigger_state = 'WAITING'
WHERE trigger_name = 'economicDataUpdateTrigger';
```

#### Cron 표현식 수정

```sql
-- ⚠️ 스케줄러 재시작 필요
UPDATE quartz_cron_triggers
SET cron_expression = '0 0 7 * * ?'  -- 매일 07:00으로 변경
WHERE trigger_name = 'economicDataUpdateTrigger';
```

### 데이터베이스 정리

#### 오래된 실행 이력 삭제

```sql
-- 실행 완료된 트리거 정보 삭제 (필요 시)
DELETE FROM quartz_fired_triggers
WHERE state = 'COMPLETE'
  AND fired_time < EXTRACT(EPOCH FROM NOW() - INTERVAL '30 days') * 1000;
```

---

## 트러블슈팅

### 문제 1: 스케줄러가 시작되지 않음

#### 증상
```
ERROR - Scheduler failed to start
```

#### 원인 및 해결

**1. PostgreSQL 연결 실패**
```bash
# 확인
docker-compose logs quantiq-core | grep -i "connection.*failed\|database.*not.*found"

# 해결
docker-compose restart postgresql
docker-compose restart quantiq-core
```

**2. Flyway 마이그레이션 실패**
```bash
# 확인
docker-compose logs quantiq-core | grep -i "flyway.*failed\|migration.*failed"

# 해결: 마이그레이션 재실행
docker-compose down -v  # 볼륨 삭제
docker-compose up -d
```

**3. 테이블이 존재하지 않음**
```bash
# 확인
docker-compose exec postgresql psql -U quantiq_user -d quantiq -c "\dt quartz_*"

# 해결: 테이블 없으면 V3 마이그레이션 확인
ls quantiq-core/src/main/resources/db/migration/V3__*.sql
```

### 문제 2: Job이 실행되지 않음

#### 증상
- 실행 시간이 되었는데 Job이 실행 안 됨
- 로그에 Job 실행 기록이 없음

#### 진단 순서

**1. 스케줄러 상태 확인**
```bash
curl http://localhost:8080/api/scheduler/status

# isRunning이 false면
curl -X POST http://localhost:8080/api/scheduler/start
```

**2. Trigger 상태 확인**
```sql
SELECT trigger_name, trigger_state
FROM quartz_triggers
WHERE job_name = 'economicDataUpdateJob';

-- PAUSED 상태면 Resume 필요
```

```bash
curl -X POST http://localhost:8080/api/scheduler/schedules/economicDataUpdateTrigger/resume
```

**3. 다음 실행 시간 확인**
```sql
SELECT
    trigger_name,
    to_timestamp(next_fire_time / 1000) AT TIME ZONE 'Asia/Seoul' as next_run
FROM quartz_triggers
WHERE job_name = 'economicDataUpdateJob';

-- next_run이 과거 시간이면 문제
```

**4. Cron 표현식 검증**
```sql
SELECT cron_expression, time_zone_id
FROM quartz_cron_triggers
WHERE trigger_name = 'economicDataUpdateTrigger';

-- Cron 표현식이 올바른지 확인
-- 온라인 Cron 검증 도구: https://crontab.guru/
```

### 문제 3: Job이 중복 실행됨

#### 증상
- 같은 Job이 동시에 여러 번 실행
- 로그에 중복 실행 기록

#### 원인 및 해결

**1. 클러스터 환경에서 락 실패**
```sql
-- 락 상태 확인
SELECT * FROM quartz_locks;

-- 오래된 락 제거 (스케줄러 정지 후)
DELETE FROM quartz_locks;
```

**2. NonConcurrent 설정 누락**
```kotlin
// Job 클래스에 어노테이션 추가
@DisallowConcurrentExecution
class EconomicDataUpdateJobAdapter : Job {
    // ...
}
```

**3. 여러 인스턴스가 클러스터링 없이 실행**
```yaml
# application.yml 확인
spring:
  quartz:
    properties:
      org.quartz.jobStore.isClustered: true  # 반드시 true
```

### 문제 4: Job 실행이 느림

#### 증상
- Job 실행 시간이 평소보다 오래 걸림
- Timeout 에러 발생

#### 진단 및 최적화

**1. 실행 시간 측정**
```bash
# 로그에서 시작-완료 시간 확인
docker-compose logs quantiq-core | grep -A 20 "경제 데이터 업데이트 시작"
```

**2. 외부 서비스 응답 시간 확인**
```bash
# Kafka 연결 상태
docker-compose exec kafka kafka-broker-api-versions.sh --bootstrap-server kafka:29092

# Data Engine 응답 시간
curl -w "@curl-format.txt" -o /dev/null -s http://localhost:8000/health
```

**3. 쓰레드 풀 확인**
```yaml
# application.yml
spring:
  quartz:
    properties:
      org.quartz.threadPool.threadCount: 10  # 기본 10, 늘릴 수 있음
```

**4. 데이터베이스 성능**
```sql
-- 테이블 통계 업데이트
ANALYZE quartz_triggers;
ANALYZE quartz_job_details;

-- 인덱스 확인
\di quartz_*
```

### 문제 5: 스케줄러 메모리 누수

#### 증상
- 장시간 실행 후 메모리 사용량 증가
- OutOfMemoryError 발생

#### 해결 방법

**1. 실행 완료 데이터 정리**
```sql
-- 주기적으로 실행
DELETE FROM quartz_fired_triggers
WHERE state IN ('COMPLETE', 'ERROR')
  AND fired_time < EXTRACT(EPOCH FROM NOW() - INTERVAL '7 days') * 1000;
```

**2. JVM 힙 메모리 설정**
```yaml
# docker-compose.yml
services:
  quantiq-core:
    environment:
      - JAVA_OPTS=-Xms512m -Xmx1024m
```

**3. Job 내 메모리 누수 확인**
```kotlin
// Job에서 대용량 데이터 처리 시 스트림 사용
override fun execute(context: JobExecutionContext?) {
    try {
        // 큰 리스트 대신 스트림 사용
        items.stream()
            .filter { ... }
            .forEach { ... }
    } finally {
        // 리소스 정리
        cleanup()
    }
}
```

---

## 성능 튜닝

### 스케줄러 최적화

#### Quartz 쓰레드 풀 조정

```yaml
spring:
  quartz:
    properties:
      # Job 동시 실행 수
      org.quartz.threadPool.threadCount: 10  # 기본 10

      # 쓰레드 우선순위
      org.quartz.threadPool.threadPriority: 5

      # 클래스 로드 전략
      org.quartz.threadPool.threadNamePrefix: QuantIQ-Scheduler-
```

#### 데이터베이스 커넥션 풀

```yaml
spring:
  datasource:
    hikari:
      maximum-pool-size: 20      # Quartz용 커넥션 확보
      minimum-idle: 5
      connection-timeout: 30000
```

### Job 실행 최적화

#### 1. 비동기 처리

```kotlin
@Component
class EconomicDataUpdateJobAdapter(
    private val economicDataUseCase: EconomicDataUseCase
) : Job {

    override fun execute(context: JobExecutionContext?) {
        // ✅ 비동기 처리 (논블로킹)
        economicDataUseCase.triggerEconomicDataUpdate()
            .thenAccept { result ->
                logger.info("✅ 완료: $result")
            }
            .exceptionally { e ->
                logger.error("❌ 실패", e)
                null
            }
            .get()  // 완료 대기
    }
}
```

#### 2. 배치 처리

```kotlin
// 대량 데이터 처리 시 배치 단위로 분할
val batchSize = 100
items.chunked(batchSize).forEach { batch ->
    processBatch(batch)
}
```

#### 3. Timeout 설정

```kotlin
// Job 실행 시간 제한
@Bean
fun jobTimeout(): Trigger {
    return TriggerBuilder.newTrigger()
        .forJob(economicDataUpdateJobDetail())
        .withSchedule(
            CronScheduleBuilder.cronSchedule("0 5 6 * * ?")
        )
        .usingJobData("timeout", 300000)  // 5분 타임아웃
        .build()
}
```

### 모니터링 및 알림

#### Slack 알림 통합 (예시)

```kotlin
@Component
class SchedulerNotificationService(
    private val slackNotifier: SlackNotificationService
) {

    @EventListener
    fun onJobExecutionFailed(event: JobExecutionFailedEvent) {
        slackNotifier.sendMessage(
            channel = "#quantiq-alerts",
            message = """
                ⚠️ Job 실행 실패
                Job: ${event.jobName}
                시간: ${event.timestamp}
                에러: ${event.error}
            """.trimIndent()
        )
    }
}
```

---

## 베스트 프랙티스

### 1. 스케줄 변경 시 주의사항

- **설정 변경 후 재시작 필수**: `QuartzConfig.kt` 변경 시 애플리케이션 재시작
- **운영 시간 피하기**: 스케줄러 재시작은 Job이 실행되지 않는 시간에 수행
- **백업**: 변경 전 데이터베이스 백업

```bash
# PostgreSQL 백업
docker-compose exec postgresql pg_dump -U quantiq_user quantiq > backup-$(date +%Y%m%d).sql
```

### 2. Job 개발 가이드

- **멱등성 보장**: 같은 Job을 여러 번 실행해도 결과가 동일해야 함
- **에러 핸들링**: 모든 예외를 catch하고 적절히 로깅
- **리소스 정리**: Job 종료 시 반드시 리소스 해제 (DB 연결, 파일 핸들 등)
- **실행 시간 최소화**: 장시간 실행 Job은 비동기 처리로 변경

### 3. 모니터링 주기

| 항목 | 확인 주기 | 조치 기준 |
|------|----------|----------|
| 스케줄러 상태 | 매 1분 | `isRunning: false` 시 알림 |
| Job 실행 성공률 | 매 1시간 | 성공률 < 95% 시 알림 |
| 실행 중인 Job | 매 5분 | 실행 시간 > 10분 시 알림 |
| 데이터베이스 용량 | 매일 | quartz 테이블 > 1GB 시 정리 |

### 4. 운영 체크리스트

#### 일일 점검
- [ ] 스케줄러 상태 확인 (`/api/scheduler/status`)
- [ ] 전날 Job 실행 이력 확인
- [ ] 에러 로그 확인
- [ ] 다음 실행 시간 확인

#### 주간 점검
- [ ] Job 실행 통계 분석
- [ ] 성능 지표 확인 (실행 시간 추이)
- [ ] 데이터베이스 용량 확인
- [ ] 로그 파일 백업 및 정리

#### 월간 점검
- [ ] Quartz 테이블 정리 (fired_triggers)
- [ ] 스케줄 최적화 검토
- [ ] 시스템 리소스 사용량 분석
- [ ] 문서 업데이트

---

## 관련 문서

- [스케줄러 아키텍처](../architecture/SCHEDULER.md)
- [이벤트 기반 아키텍처 가이드](../architecture/EVENT_DRIVEN_GUIDE.md)
- [로컬 테스트 가이드](./LOCAL_TEST_GUIDE.md)

---

## 자주 사용하는 명령어 치트시트

```bash
# 스케줄러 상태 확인
curl http://localhost:8080/api/scheduler/status

# 모든 스케줄 조회
curl http://localhost:8080/api/scheduler/schedules

# 스케줄 일시 중지
curl -X POST http://localhost:8080/api/scheduler/schedules/{triggerName}/pause

# 스케줄 재개
curl -X POST http://localhost:8080/api/scheduler/schedules/{triggerName}/resume

# 스케줄러 로그 확인
docker-compose logs -f quantiq-core | grep -E "(Scheduler|Job|경제|분석)"

# 다음 실행 시간 확인 (PostgreSQL)
docker-compose exec postgresql psql -U quantiq_user -d quantiq -c "
SELECT trigger_name,
       to_timestamp(next_fire_time / 1000) AT TIME ZONE 'Asia/Seoul' as next_run
FROM quartz_triggers ORDER BY next_fire_time;"

# 실행 중인 Job 확인
docker-compose exec postgresql psql -U quantiq_user -d quantiq -c "
SELECT * FROM quartz_fired_triggers WHERE state = 'EXECUTING';"

# 에러 로그 필터링
docker-compose logs quantiq-core --since 24h | grep -i "error.*job\|❌"

# 스케줄러 재시작
docker-compose restart quantiq-core
```

---

**마지막 업데이트**: 2026-02-01
**버전**: 2.0 (Vertex AI 통합 및 스케줄 최적화)
**작성자**: QuantIQ Development Team

**주요 변경사항 (v2.0):**
- 경제 데이터 수집 시간 변경: 06:05 → 22:00 (미국 경제 지표 발표 타이밍 최적화)
- Google Vertex AI CustomJob 통합 (Fine-tuning 모드로 83% 성능 개선)
- 자동 매수 시간 변경: 23:50 → 00:30 (시장 개장 1시간 후, 변동성 안정화)
- 전체 스케줄 재구성: 데이터 수집 → 예측 → 검증 → 매수 → 재검증 플로우
- 스케줄 구성 섹션 신규 추가 (미국 경제 지표 발표 시간 및 변동성 패턴 분석)
