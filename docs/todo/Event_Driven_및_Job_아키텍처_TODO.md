# Event-Driven & Job ì•„í‚¤í…ì²˜ TODO

## âœ… Phase 1: Event-Driven Architecture êµ¬í˜„ ì™„ë£Œ (2026-01-31)

### ì™„ë£Œ í•­ëª©

#### 1. Event Schema í‘œì¤€í™”
- [x] í†µì¼ëœ ì´ë²¤íŠ¸ êµ¬ì¡° ì •ì˜ (`eventId`, `eventType`, `timestamp`, `source`, `payload`)
- [x] ë„ë©”ì¸ë³„ í† í”½ ëª…ëª… ê·œì¹™: `quantiq.<domain>.<event-type>`
- [x] Kotlin Event Schema êµ¬í˜„ (`events/EventSchema.kt`)
- [x] Python Event Schema êµ¬í˜„ (`events/schema.py`)
- [x] ë¬¸ì„œí™”: `docs/architecture/EVENT_SCHEMA.md`

#### 2. Kotlin (quantiq-core) Event ì‹œìŠ¤í…œ
- [x] ë„ë©”ì¸ë³„ Event Publisher êµ¬í˜„
  - [x] `EconomicEventPublisher`
  - [x] `StockEventPublisher`
  - [x] `TradingEventPublisher`
  - [x] `AnalysisEventPublisher`
- [x] Kafka Producer/Consumer ì„¤ì • ìµœì í™”
  - [x] `acks=all`, `idempotence=true` (ì •í™•í•œ 1íšŒ ì „ì†¡)
  - [x] ì••ì¶•: `snappy`
  - [x] ì¬ì‹œë„: 3íšŒ
- [x] Event Listener êµ¬í˜„ (`KafkaMessageListener.kt`)
  - [x] ë¶„ì„ ì™„ë£Œ ì´ë²¤íŠ¸
  - [x] ê²½ì œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ
  - [x] ê²½ì œ ë°ì´í„° ë™ê¸°í™” ì‹¤íŒ¨
  - [x] ë§¤ë§¤ ì‹ í˜¸ ê°ì§€

#### 3. Python (quantiq-data-engine) Event ì‹œìŠ¤í…œ
- [x] Event Handler êµ¬í˜„
  - [x] `EconomicEventHandler`
  - [x] `StockEventHandler`
  - [x] `AnalysisEventHandler`
- [x] Event Router êµ¬í˜„ (í† í”½ë³„ í•¸ë“¤ëŸ¬ ë¼ìš°íŒ…)
- [x] Event Publisher ê°œì„  (Singleton íŒ¨í„´)
- [x] main.py Consumer ë©€í‹° í† í”½ êµ¬ë…

#### 4. REST â†’ Event ì „í™˜
- [x] `EconomicDataSchedulerService` â†’ Event ë°œí–‰
- [x] Backward Compatibility (Legacy í† í”½ ì§€ì›)

#### 5. ë¶„ì„ ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ êµ¬í˜„ (2026-01-31 ì¶”ê°€)
- [x] ë¶„ì„ ìš”ì²­ ì´ë²¤íŠ¸ (Kotlin â†’ Python)
  - [x] `analysis.technical.request` - ê¸°ìˆ ì  ë¶„ì„ ìš”ì²­
  - [x] `analysis.sentiment.request` - ë‰´ìŠ¤ ê°ì • ë¶„ì„ ìš”ì²­
  - [x] `analysis.combined.request` - í†µí•© ë¶„ì„ ìš”ì²­
- [x] ë¶„ì„ ì™„ë£Œ ì´ë²¤íŠ¸ (Python â†’ Kotlin)
  - [x] `analysis.technical.completed` - ê¸°ìˆ ì  ë¶„ì„ ì™„ë£Œ
  - [x] `analysis.sentiment.completed` - ê°ì • ë¶„ì„ ì™„ë£Œ
  - [x] `analysis.completed` - í†µí•© ë¶„ì„ ì™„ë£Œ
- [x] Slack ìŠ¤ë ˆë“œ íŒ¨í„´ êµ¬í˜„
  - [x] Kotlin: Slack ìŠ¤ë ˆë“œ ìƒì„± ë° threadTs íšë“
  - [x] Kotlin: Kafka ë©”ì‹œì§€ì— threadTs í¬í•¨
  - [x] Python: threadTsë¡œ ìŠ¤ë ˆë“œ ë‹µê¸€ í˜•íƒœë¡œ ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
- [x] Python ë¶„ì„ ì„œë¹„ìŠ¤
  - [x] `RecommendationService` - í†µí•© ë¶„ì„ ë ˆì´ì–´
  - [x] `TechnicalAnalysisService` - SMA, RSI, MACD ê³„ì‚°
  - [x] `SentimentAnalysisService` - Alpha Vantage NEWS_SENTIMENT API
  - [x] í†µí•© ì ìˆ˜ ê³„ì‚°: ê¸°ìˆ ì (70%) + ê°ì •(30%) ê°€ì¤‘í‰ê· 
- [x] ìŠ¤ì¼€ì¤„ëŸ¬ Job êµ¬í˜„
  - [x] `CombinedAnalysisJobAdapter` (23:45) - í†µí•© ë¶„ì„
  - [x] Domain/Application/Adapter ë ˆì´ì–´ êµ¬í˜„

#### 6. ë¬¸ì„œí™”
- [x] Event Schema ë¬¸ì„œ
- [x] Event-Driven ì‚¬ìš© ê°€ì´ë“œ
- [x] í…ŒìŠ¤íŠ¸ ë°©ë²• ë° íŠ¸ëŸ¬ë¸”ìŠˆíŒ…
- [x] ë¶„ì„ ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ (2026-01-31 ì¶”ê°€)
  - [x] ê¸°ìˆ ì /ê°ì •/í†µí•© ë¶„ì„ ì´ë²¤íŠ¸ ì •ì˜
  - [x] Slack ìŠ¤ë ˆë“œ íŒ¨í„´ ë¬¸ì„œí™”
  - [x] í†µí•© ì ìˆ˜ ê³„ì‚°ì‹ ë¬¸ì„œí™”

### êµ¬í˜„ëœ ì´ë²¤íŠ¸ Flow

```
Quartz Scheduler â†’ quantiq.economic.data.sync.requested â†’ Data Engine
Data Engine â†’ quantiq.economic.data.updated â†’ Quantiq Core
Data Engine â†’ quantiq.trading.signal.detected â†’ Quantiq Core â†’ Auto Trading
```

---

## ğŸš€ Phase 2: Job-based ì•„í‚¤í…ì²˜ ì „í™˜ (ë¦¬ì†ŒìŠ¤ ìµœì í™”)

### ëª©í‘œ

**í˜„ì¬**: Python Data Engineì´ í•­ìƒ ì‹¤í–‰ë˜ë©° Kafka Consumerë¡œ ë©”ì‹œì§€ ëŒ€ê¸° (ë¦¬ì†ŒìŠ¤ ìƒì‹œ ì‚¬ìš©)

**ê°œì„ **: í•„ìš”í•  ë•Œë§Œ Python Jobì„ ì‹¤í–‰í•˜ì—¬ ë¦¬ì†ŒìŠ¤ íš¨ìœ¨í™”

### êµ¬í˜„ ë°©ì•ˆ

#### ì˜µì…˜ 1: Celery + Kafka (ì¶”ì²œ â­)

**ì¥ì **:
- Python ìƒíƒœê³„ í‘œì¤€ ë¶„ì‚° ì‘ì—… í
- Kafka ë©”ì‹œì§€ â†’ Celery Task ìë™ íŠ¸ë¦¬ê±°
- ì‘ì—… ì¬ì‹œë„, ìš°ì„ ìˆœìœ„, ìŠ¤ì¼€ì¤„ë§ ê¸°ë³¸ ì§€ì›
- ëª¨ë‹ˆí„°ë§ ë„êµ¬ (Flower) ì œê³µ

**êµ¬ì¡°**:
```
quantiq-core â†’ Kafka Event â†’ Celery Worker â†’ Python Job ì‹¤í–‰ â†’ ê²°ê³¼ ì´ë²¤íŠ¸ ë°œí–‰
```

**êµ¬í˜„ ë‹¨ê³„**:
1. [ ] Celery + Redis ì„¤ì¹˜ ë° ì„¤ì •
2. [ ] Kafka Consumer â†’ Celery Task Trigger ë¸Œë¦¿ì§€ êµ¬í˜„
3. [ ] ë„ë©”ì¸ë³„ Celery Task ì •ì˜
   - [ ] `tasks/economic_data_task.py`
   - [ ] `tasks/stock_analysis_task.py`
   - [ ] `tasks/prediction_task.py`
4. [ ] Celery Worker Docker ì»¨í…Œì´ë„ˆ ì¶”ê°€
5. [ ] Flower ëª¨ë‹ˆí„°ë§ UI ì„¤ì •

**ì˜ˆìƒ ì½”ë“œ**:
```python
# tasks/economic_data_task.py
from celery import Celery

app = Celery('quantiq', broker='redis://redis:6379/0')

@app.task(bind=True, max_retries=3)
def collect_economic_data_task(self, request_id, data_types):
    try:
        collect_economic_data()
        # ì™„ë£Œ ì´ë²¤íŠ¸ ë°œí–‰
        EventPublisher.publish(EventTopics.ECONOMIC_DATA_UPDATED, ...)
    except Exception as e:
        self.retry(exc=e, countdown=60)
```

**docker-compose ì¶”ê°€**:
```yaml
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  celery-worker:
    build:
      context: ./quantiq-data-engine
    command: celery -A tasks worker --loglevel=info
    depends_on:
      - redis
      - kafka

  flower:
    build:
      context: ./quantiq-data-engine
    command: celery -A tasks flower
    ports:
      - "5555:5555"
```

---

#### ì˜µì…˜ 2: Kubernetes CronJob + Event Trigger

**ì¥ì **:
- K8s ë„¤ì´í‹°ë¸Œ (ì´ë¯¸ K8s ì‚¬ìš© ì¤‘ì´ë©´ ì¶”ì²œ)
- ìë™ ìŠ¤ì¼€ì¼ë§, ë¦¬ì†ŒìŠ¤ ì œí•œ
- Job ì‹¤í–‰ íˆìŠ¤í† ë¦¬ ê´€ë¦¬

**êµ¬ì¡°**:
```
Kafka Event â†’ K8s Job Controller â†’ Python Pod ìƒì„± â†’ ì‘ì—… ì‹¤í–‰ â†’ Pod ì¢…ë£Œ
```

**êµ¬í˜„ ë‹¨ê³„**:
1. [ ] Kubernetes í´ëŸ¬ìŠ¤í„° ì„¤ì •
2. [ ] Job Controller êµ¬í˜„ (Kafka Consumer â†’ K8s Job ìƒì„±)
3. [ ] Python Job Pod ì´ë¯¸ì§€ ìµœì í™”
4. [ ] CronJob ìŠ¤ì¼€ì¤„ ì •ì˜ (ì •ê¸° ì‘ì—…)
5. [ ] Event-triggered Job ì •ì˜ (on-demand ì‘ì—…)

**ì˜ˆìƒ ì½”ë“œ**:
```yaml
# k8s/jobs/economic-data-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: economic-data-collection
spec:
  template:
    spec:
      containers:
      - name: data-collector
        image: quantiq-data-engine:latest
        command: ["python", "jobs/collect_economic_data.py"]
        env:
        - name: REQUEST_ID
          value: "req-12345"
      restartPolicy: OnFailure
```

---

#### ì˜µì…˜ 3: Docker + Kafka Consumer + Process Pool

**ì¥ì **:
- í˜„ì¬ ì¸í”„ë¼ ê·¸ëŒ€ë¡œ í™œìš©
- ë³µì¡ë„ ë‚®ìŒ
- ë¹ ë¥¸ êµ¬í˜„

**êµ¬ì¡°**:
```
Kafka Consumer (í•­ìƒ ì‹¤í–‰) â†’ Process Pool â†’ Worker Process ìƒì„±/ì¢…ë£Œ
```

**êµ¬í˜„ ë‹¨ê³„**:
1. [ ] Python multiprocessing.Pool êµ¬í˜„
2. [ ] Kafka ë©”ì‹œì§€ ìˆ˜ì‹  ì‹œ Worker Process ì‹¤í–‰
3. [ ] ì‘ì—… ì™„ë£Œ í›„ Process ì¢…ë£Œ
4. [ ] Process Pool í¬ê¸° ë™ì  ì¡°ì •

**ì˜ˆìƒ ì½”ë“œ**:
```python
from multiprocessing import Pool

def worker(event_data):
    # ì‘ì—… ì‹¤í–‰
    collect_economic_data()
    # ì™„ë£Œ ì´ë²¤íŠ¸ ë°œí–‰
    EventPublisher.publish(...)

# main.py
pool = Pool(processes=4)

while True:
    msg = consumer.poll(1.0)
    if msg:
        pool.apply_async(worker, (msg,))
```

---

#### ì˜µì…˜ 4: AWS Lambda / Cloud Functions (Serverless)

**ì¥ì **:
- ì™„ì „ ìë™ ìŠ¤ì¼€ì¼ë§
- ì‚¬ìš©í•œ ë§Œí¼ë§Œ ê³¼ê¸ˆ
- ê´€ë¦¬ ì˜¤ë²„í—¤ë“œ ì œë¡œ

**ë‹¨ì **:
- í´ë¼ìš°ë“œ ì¢…ì†
- Cold Start ì§€ì—°
- ì‹¤í–‰ ì‹œê°„ ì œí•œ (15ë¶„)

**êµ¬í˜„ ë‹¨ê³„**:
1. [ ] Lambda í•¨ìˆ˜ ì‘ì„±
2. [ ] Kafka â†’ Lambda Trigger ì„¤ì • (EventBridge)
3. [ ] í™˜ê²½ ë³€ìˆ˜ ë° ì‹œí¬ë¦¿ ê´€ë¦¬
4. [ ] VPC ì„¤ì • (DB ì ‘ê·¼)

---

### ì„±ëŠ¥ ë¹„êµ

| ë°©ì‹ | ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ | ë³µì¡ë„ | í™•ì¥ì„± | ëª¨ë‹ˆí„°ë§ | ì¶”ì²œë„ |
|------|------------|--------|--------|----------|--------|
| **Celery + Redis** | â­â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | âœ… ì¶”ì²œ |
| K8s CronJob | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | ğŸŸ¡ K8s í™˜ê²½ ì‹œ |
| Process Pool | â­â­â­ | â­â­ | â­â­â­ | â­â­ | ğŸŸ¡ ë¹ ë¥¸ êµ¬í˜„ |
| AWS Lambda | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | ğŸ”´ í´ë¼ìš°ë“œ í™˜ê²½ ì‹œ |

---

## ğŸ“‹ Phase 2 êµ¬í˜„ ê³„íš (Celery ë°©ì‹)

### Step 1: Celery ê¸°ë³¸ ì„¤ì •
- [ ] Redis ì¶”ê°€ (docker-compose.yml)
- [ ] Celery ì„¤ì¹˜ (`requirements.txt`)
- [ ] Celery app ì´ˆê¸°í™” (`celeryconfig.py`)

### Step 2: Task ì •ì˜
- [ ] `tasks/__init__.py`
- [ ] `tasks/economic_data_task.py`
- [ ] `tasks/stock_analysis_task.py`
- [ ] `tasks/prediction_task.py`

### Step 3: Kafka â†’ Celery ë¸Œë¦¿ì§€
- [ ] `bridges/kafka_celery_bridge.py`
  - Kafka Consumer â†’ Celery Task íŠ¸ë¦¬ê±°
  - ì´ë²¤íŠ¸ íƒ€ì…ë³„ Task ë§¤í•‘

### Step 4: Worker ì„¤ì •
- [ ] Celery Worker Dockerfile
- [ ] docker-composeì— worker ì¶”ê°€
- [ ] ë¦¬ì†ŒìŠ¤ ì œí•œ ì„¤ì •

### Step 5: ëª¨ë‹ˆí„°ë§
- [ ] Flower UI ì„¤ì •
- [ ] Task ì‹¤í–‰ ë¡œê·¸
- [ ] ì‹¤íŒ¨ Task ì¬ì‹œë„ ì •ì±…

### Step 6: ê¸°ì¡´ ì½”ë“œ ë§ˆì´ê·¸ë ˆì´ì…˜
- [ ] `main.py` â†’ Kafka-Celery ë¸Œë¦¿ì§€ë¡œ ë³€ê²½
- [ ] Event Handler â†’ Celery Taskë¡œ ì „í™˜
- [ ] ê¸°ì¡´ Consumer ì½”ë“œ ì œê±°

### Step 7: í…ŒìŠ¤íŠ¸
- [ ] Task ì‹¤í–‰ í…ŒìŠ¤íŠ¸
- [ ] ì¬ì‹œë„ ë¡œì§ í…ŒìŠ¤íŠ¸
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰)

---

## ğŸ¯ ì˜ˆìƒ íš¨ê³¼

### í˜„ì¬ (Always-On Consumer)
```
quantiq-data-engine:
  CPU: 0.5 core (ìƒì‹œ)
  Memory: 512MB (ìƒì‹œ)
  ì‹¤í–‰ ì‹œê°„: 24ì‹œê°„
```

### ê°œì„  í›„ (Job-based)
```
Kafka Consumer (lightweight):
  CPU: 0.1 core (ìƒì‹œ)
  Memory: 128MB (ìƒì‹œ)

Celery Worker (í•„ìš” ì‹œ):
  CPU: 1 core (ì‘ì—… ì‹œ)
  Memory: 512MB (ì‘ì—… ì‹œ)
  ì‹¤í–‰ ì‹œê°„: ì‘ì—… ì‹œê°„ë§Œ (ì˜ˆ: 1ì¼ 30ë¶„)

ë¦¬ì†ŒìŠ¤ ì ˆê°: ~70-80%
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### Celery
- ê³µì‹ ë¬¸ì„œ: https://docs.celeryq.dev/
- Kafka Integration: https://docs.celeryq.dev/en/stable/userguide/configuration.html
- Best Practices: https://docs.celeryq.dev/en/stable/userguide/tasks.html

### Kubernetes Jobs
- Job ê°€ì´ë“œ: https://kubernetes.io/docs/concepts/workloads/controllers/job/
- CronJob ê°€ì´ë“œ: https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/

### ì•„í‚¤í…ì²˜ íŒ¨í„´
- Event-Driven Microservices: https://martinfowler.com/articles/201701-event-driven.html
- Job Queue Patterns: https://aws.amazon.com/blogs/compute/orchestrating-a-job-queue-with-aws-batch/

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **Stateless Job ì„¤ê³„**
   - Jobì€ ìƒíƒœë¥¼ ìœ ì§€í•˜ì§€ ì•Šì•„ì•¼ í•¨
   - ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ëŠ” ë©”ì‹œì§€ ë˜ëŠ” DBì—ì„œ ë¡œë“œ

2. **Idempotency (ë©±ë“±ì„±)**
   - ê°™ì€ Jobì´ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰ë˜ì–´ë„ ì•ˆì „í•´ì•¼ í•¨
   - ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€ ë¡œì§ í•„ìš”

3. **ì—ëŸ¬ í•¸ë“¤ë§**
   - Retry ì •ì±… ëª…í™•íˆ ì •ì˜
   - Dead Letter Queue ì„¤ì •
   - ì‹¤íŒ¨ ì•Œë¦¼ (Slack)

4. **ëª¨ë‹ˆí„°ë§**
   - Job ì‹¤í–‰ ì‹œê°„ ì¶”ì 
   - ì‹¤íŒ¨ìœ¨ ëª¨ë‹ˆí„°ë§
   - ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëŒ€ì‹œë³´ë“œ

---

**ì‘ì„±ì¼**: 2026-01-31
**í˜„ì¬ ìƒíƒœ**: Phase 1 ì™„ë£Œ, Phase 2 ê³„íš ìˆ˜ë¦½
**ë‹¤ìŒ ì•¡ì…˜**: Celery ê¸°ë³¸ ì„¤ì • ë° POC êµ¬í˜„
