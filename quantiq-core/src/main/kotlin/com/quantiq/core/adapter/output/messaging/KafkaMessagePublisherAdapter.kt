package com.quantiq.core.adapter.output.messaging

import com.quantiq.core.domain.economic.port.output.MessagePublisher
import com.quantiq.core.domain.model.AnalysisRequest
import com.quantiq.core.domain.model.EconomicDataUpdateRequest
import com.fasterxml.jackson.databind.ObjectMapper
import org.slf4j.LoggerFactory
import org.springframework.kafka.core.KafkaTemplate
import org.springframework.stereotype.Component
import java.util.*

/**
 * Kafka Message Publisher Adapter (Output Adapter)
 * MessagePublisher ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•˜ì—¬ Kafkaì™€ ì—°ë™í•©ë‹ˆë‹¤.
 */
@Component
class KafkaMessagePublisherAdapter(
    private val kafkaTemplate: KafkaTemplate<String, String>,
    private val objectMapper: ObjectMapper
) : MessagePublisher {

    private val logger = LoggerFactory.getLogger(this::class.java)

    override fun publishEconomicDataUpdateRequest(
        topic: String,
        request: EconomicDataUpdateRequest
    ) {
        try {
            // ì´ë²¤íŠ¸ ë˜í¼ ìƒì„± (eventType í¬í•¨)
            val event = mapOf(
                "eventId" to UUID.randomUUID().toString(),
                "eventType" to topic,  // í† í”½ì„ eventTypeìœ¼ë¡œ ì‚¬ìš©
                "version" to "1.0",
                "timestamp" to request.timestamp,
                "source" to request.source,
                "payload" to mapOf(
                    "requestId" to request.requestId,
                    "source" to request.source,
                    "timestamp" to request.timestamp,
                    "threadTs" to request.threadTs  // Slack ìŠ¤ë ˆë“œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
                )
            )

            val eventJson = objectMapper.writeValueAsString(event)

            logger.debug("ğŸ“¤ Kafka ë©”ì‹œì§€ ìƒì„±: $eventJson")

            kafkaTemplate.send(
                topic,
                request.requestId,
                eventJson
            )
            logger.info("Kafka ë©”ì‹œì§€ ë°œí–‰ ì„±ê³µ: topic=$topic, requestId=${request.requestId}")
        } catch (e: Exception) {
            logger.error("Kafka ë©”ì‹œì§€ ë°œí–‰ ì‹¤íŒ¨: topic=$topic", e)
            throw e
        }
    }

    override fun publishAnalysisRequest(
        topic: String,
        request: AnalysisRequest
    ) {
        try {
            // ì´ë²¤íŠ¸ ë˜í¼ ìƒì„± (eventType í¬í•¨)
            val event = mapOf(
                "eventId" to UUID.randomUUID().toString(),
                "eventType" to topic,  // í† í”½ì„ eventTypeìœ¼ë¡œ ì‚¬ìš©
                "version" to "1.0",
                "timestamp" to request.timestamp,
                "source" to request.source,
                "payload" to mapOf(
                    "requestId" to request.requestId,
                    "source" to request.source,
                    "timestamp" to request.timestamp,
                    "threadTs" to request.threadTs,  // Slack ìŠ¤ë ˆë“œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
                    "analysisType" to request.analysisType,
                    "targetDate" to request.targetDate  // ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ ì¶”ê°€
                )
            )

            val eventJson = objectMapper.writeValueAsString(event)

            logger.debug("ğŸ“¤ Kafka ë©”ì‹œì§€ ìƒì„±: $eventJson")

            kafkaTemplate.send(
                topic,
                request.requestId,
                eventJson
            )
            logger.info("Kafka ë©”ì‹œì§€ ë°œí–‰ ì„±ê³µ: topic=$topic, requestId=${request.requestId}, type=${request.analysisType}")
        } catch (e: Exception) {
            logger.error("Kafka ë©”ì‹œì§€ ë°œí–‰ ì‹¤íŒ¨: topic=$topic", e)
            throw e
        }
    }
}
