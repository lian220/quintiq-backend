"""
Quantiq Data Engine - Feature-based Architecture
"""
import logging
import json
import time
import threading
from fastapi import FastAPI
import uvicorn
from confluent_kafka import Consumer, KafkaError
from datetime import datetime
from pytz import timezone

from src.core.config import settings
from src.core.database import MongoDB
from src.features.economic_data.router import router as economic_router
from src.features.economic_data.service import EconomicDataService
from src.services.recommendation_service import RecommendationService
from src.services.slack_notifier import SlackNotifier
from src.core.kafka import KafkaEventPublisher

KST = timezone('Asia/Seoul')

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# FastAPI app
app = FastAPI(title="Quantiq Data Engine")

# Include routers
app.include_router(economic_router)


@app.get("/")
def read_root():
    return {
        "status": "Quantiq Data Engine is running (Feature-based Architecture)",
        "kafka_topics": [
            "economic.data.update.request"
        ],
        "timestamp": datetime.now(KST).isoformat()
    }


@app.get("/health")
def health_check():
    return {"status": "alive", "timestamp": datetime.now(KST).isoformat()}


def run_api():
    logger.info("Starting Data Engine API server on port 8000")
    uvicorn.run(app, host="0.0.0.0", port=8000)


def main():
    logger.info("Quantiq Data Engine Started (Feature-based Architecture)")

    # Start API server in a separate thread
    api_thread = threading.Thread(target=run_api, daemon=True)
    api_thread.start()

    # 1. Start MongoDB connection
    db = MongoDB.get_db()
    if db is None:
        logger.error("Failed to connect to MongoDB")
        return

    # 2. Setup Kafka Consumer
    conf = {
        'bootstrap.servers': settings.KAFKA_BOOTSTRAP_SERVERS,
        'group.id': 'quantiq-data-engine-fresh',  # Fresh consumer group for clean start
        'auto.offset.reset': 'earliest'
    }

    # Wait for Kafka to be ready
    time.sleep(10)

    consumer = Consumer(conf)

    # í† í”½ êµ¬ë… (ê²½ì œ ë°ì´í„° + ë¶„ì„ ìš”ì²­)
    topics = [
        settings.KAFKA_TOPIC_ECONOMIC_DATA_UPDATE_REQUEST,
        "analysis.technical.request",
        "analysis.sentiment.request",
        "analysis.combined.request"
    ]
    consumer.subscribe(topics)
    logger.info(f"Subscribed to topics: {topics}")

    # Services ì´ˆê¸°í™”
    economic_service = EconomicDataService()
    recommendation_service = RecommendationService()

    try:
        while True:
            msg = consumer.poll(1.0)

            if msg is None:
                continue
            if msg.error():
                if msg.error().code() == KafkaError._PARTITION_EOF:
                    continue
                else:
                    logger.error(f"Consumer error: {msg.error()}")
                    continue

            try:
                topic_name = msg.topic()
                message = json.loads(msg.value().decode('utf-8'))
                logger.info(f"Received request from topic '{topic_name}': {message}")

                # ê²½ì œ ë°ì´í„° ì—…ë°ì´íŠ¸ ìš”ì²­ ì²˜ë¦¬
                if topic_name == settings.KAFKA_TOPIC_ECONOMIC_DATA_UPDATE_REQUEST:
                    # payload í•„ë“œì—ì„œ ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ
                    payload = message.get("payload", message)
                    request_id = payload.get("requestId", "unknown")
                    source = payload.get("source", "kafka")
                    thread_ts = payload.get("threadTs")  # Kotlinì—ì„œ ì „ë‹¬ë°›ì€ ìŠ¤ë ˆë“œ íƒ€ì„ìŠ¤íƒ¬í”„

                    logger.info("=" * 80)
                    logger.info("ê²½ì œ ë°ì´í„° ì—…ë°ì´íŠ¸ Kafka ë©”ì‹œì§€ ìˆ˜ì‹ ")
                    logger.info(f"Request ID: {request_id}")
                    logger.info(f"Thread TS: {thread_ts}")
                    logger.info("=" * 80)

                    # ğŸ”” ìˆ˜ì§‘ ì‹œì‘ ì•Œë¦¼ (ìŠ¤ë ˆë“œ ë‹µê¸€)
                    SlackNotifier.notify_economic_data_collection_start(request_id, source, thread_ts)

                    start_time = time.time()
                    try:
                        # Service í˜¸ì¶œ
                        result = economic_service.collect_economic_data()
                        elapsed_time = time.time() - start_time

                        logger.info("âœ… ê²½ì œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")

                        # ìˆ˜ì§‘ ê²°ê³¼ ë°ì´í„° êµ¬ì„±
                        collection_summary = {
                            "duration": f"{elapsed_time:.2f}ì´ˆ",
                            "fred_collected": result.get("fred_collected", 0),
                            "yahoo_collected": result.get("yahoo_collected", 0),
                            "total_indicators": result.get("fred_collected", 0) + result.get("yahoo_collected", 0)
                        }

                        # ğŸ”” ìˆ˜ì§‘ ì™„ë£Œ ì•Œë¦¼ (ìŠ¤ë ˆë“œ ë‹µê¸€)
                        SlackNotifier.notify_economic_data_collection_success(
                            request_id,
                            collection_summary,
                            thread_ts
                        )

                        # ì™„ë£Œ ì´ë²¤íŠ¸ ë°œí–‰
                        KafkaEventPublisher.publish("ECONOMIC_DATA_UPDATED", {
                            "status": "success",
                            "timestamp": datetime.now(KST).isoformat(),
                            "requestId": request_id,
                            "duration": elapsed_time
                        })
                    except Exception as e:
                        logger.error(f"âŒ ê²½ì œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

                        # ğŸ”” ì˜¤ë¥˜ ì•Œë¦¼ (ìŠ¤ë ˆë“œ ë‹µê¸€)
                        SlackNotifier.notify_economic_data_collection_error(request_id, str(e), thread_ts)

                        # ì˜¤ë¥˜ ì´ë²¤íŠ¸ ë°œí–‰
                        KafkaEventPublisher.publish("ECONOMIC_DATA_UPDATE_FAILED", {
                            "status": "failed",
                            "timestamp": datetime.now(KST).isoformat(),
                            "requestId": request_id,
                            "error": str(e)
                        })
                        raise

                # ê¸°ìˆ ì  ë¶„ì„ ìš”ì²­ ì²˜ë¦¬
                elif topic_name == "analysis.technical.request":
                    payload = message.get("payload", message)
                    request_id = payload.get("requestId", "unknown")
                    thread_ts = payload.get("threadTs")  # Kotlinì—ì„œ ì „ë‹¬ë°›ì€ ìŠ¤ë ˆë“œ íƒ€ì„ìŠ¤íƒ¬í”„

                    logger.info("=" * 80)
                    logger.info("ê¸°ìˆ ì  ë¶„ì„ ìš”ì²­ Kafka ë©”ì‹œì§€ ìˆ˜ì‹ ")
                    logger.info(f"Request ID: {request_id}")
                    logger.info(f"Thread TS: {thread_ts}")
                    logger.info("=" * 80)

                    start_time = time.time()
                    try:
                        # Service í˜¸ì¶œ
                        result = recommendation_service.run_technical_analysis(request_id, thread_ts)
                        elapsed_time = time.time() - start_time

                        logger.info("âœ… ê¸°ìˆ ì  ë¶„ì„ ì™„ë£Œ")

                        # ì™„ë£Œ ì´ë²¤íŠ¸ ë°œí–‰
                        KafkaEventPublisher.publish("ANALYSIS_TECHNICAL_COMPLETED", {
                            "status": "success",
                            "timestamp": datetime.now(KST).isoformat(),
                            "requestId": request_id,
                            "duration": elapsed_time,
                            "result": result
                        })
                    except Exception as e:
                        logger.error(f"âŒ ê¸°ìˆ ì  ë¶„ì„ ì‹¤íŒ¨: {e}")
                        KafkaEventPublisher.publish("ANALYSIS_TECHNICAL_FAILED", {
                            "status": "failed",
                            "timestamp": datetime.now(KST).isoformat(),
                            "requestId": request_id,
                            "error": str(e)
                        })

                # ê°ì • ë¶„ì„ ìš”ì²­ ì²˜ë¦¬
                elif topic_name == "analysis.sentiment.request":
                    payload = message.get("payload", message)
                    request_id = payload.get("requestId", "unknown")
                    thread_ts = payload.get("threadTs")

                    logger.info("=" * 80)
                    logger.info("ë‰´ìŠ¤ ê°ì • ë¶„ì„ ìš”ì²­ Kafka ë©”ì‹œì§€ ìˆ˜ì‹ ")
                    logger.info(f"Request ID: {request_id}")
                    logger.info(f"Thread TS: {thread_ts}")
                    logger.info("=" * 80)

                    start_time = time.time()
                    try:
                        result = recommendation_service.run_sentiment_analysis(request_id, thread_ts)
                        elapsed_time = time.time() - start_time

                        logger.info("âœ… ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì™„ë£Œ")

                        KafkaEventPublisher.publish("ANALYSIS_SENTIMENT_COMPLETED", {
                            "status": "success",
                            "timestamp": datetime.now(KST).isoformat(),
                            "requestId": request_id,
                            "duration": elapsed_time,
                            "result": result
                        })
                    except Exception as e:
                        logger.error(f"âŒ ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
                        KafkaEventPublisher.publish("ANALYSIS_SENTIMENT_FAILED", {
                            "status": "failed",
                            "timestamp": datetime.now(KST).isoformat(),
                            "requestId": request_id,
                            "error": str(e)
                        })

                # í†µí•© ë¶„ì„ ìš”ì²­ ì²˜ë¦¬
                elif topic_name == "analysis.combined.request":
                    payload = message.get("payload", message)
                    request_id = payload.get("requestId", "unknown")
                    thread_ts = payload.get("threadTs")

                    logger.info("=" * 80)
                    logger.info("í†µí•© ë¶„ì„ ìš”ì²­ Kafka ë©”ì‹œì§€ ìˆ˜ì‹ ")
                    logger.info(f"Request ID: {request_id}")
                    logger.info(f"Thread TS: {thread_ts}")
                    logger.info("=" * 80)

                    start_time = time.time()
                    try:
                        result = recommendation_service.run_combined_analysis(request_id, thread_ts)
                        elapsed_time = time.time() - start_time

                        logger.info("âœ… í†µí•© ë¶„ì„ ì™„ë£Œ")

                        KafkaEventPublisher.publish("ANALYSIS_COMPLETED", {
                            "status": "success",
                            "timestamp": datetime.now(KST).isoformat(),
                            "requestId": request_id,
                            "duration": elapsed_time,
                            "result": result
                        })
                    except Exception as e:
                        logger.error(f"âŒ í†µí•© ë¶„ì„ ì‹¤íŒ¨: {e}")
                        KafkaEventPublisher.publish("ANALYSIS_FAILED", {
                            "status": "failed",
                            "timestamp": datetime.now(KST).isoformat(),
                            "requestId": request_id,
                            "error": str(e)
                        })

            except Exception as e:
                logger.error(f"Error processing message: {e}")

    except KeyboardInterrupt:
        pass
    finally:
        consumer.close()


if __name__ == "__main__":
    main()
